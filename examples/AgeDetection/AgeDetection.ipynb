{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题描述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的任务是从一个人的面部特征来预测他的年龄(用“Young”“Middle ”“Old”表示)，我们训练的数据集大约有19906多张照片及其每张图片对应的年龄（全是阿三的头像。。。），测试集有6636张图片，首先我们加载数据集，然后我们通过深度学习框架Keras建立、编译、训练模型，预测出6636张人物头像对应的年龄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引入所需要模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID   Class\n",
      "0    377.jpg  MIDDLE\n",
      "1  17814.jpg   YOUNG\n",
      "2  21283.jpg  MIDDLE\n",
      "3  16496.jpg   YOUNG\n",
      "4   4487.jpg  MIDDLE\n",
      "          ID\n",
      "0  25321.jpg\n",
      "1    989.jpg\n",
      "2  19277.jpg\n",
      "3  13093.jpg\n",
      "4   5367.jpg\n"
     ]
    }
   ],
   "source": [
    "root_dir=os.path.abspath('E:/data/age')\n",
    "train=pd.read_csv(os.path.join(root_dir,'train.csv'))\n",
    "test=pd.read_csv(os.path.join(root_dir,'test.csv'))\n",
    "\n",
    "print(train.head())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机读取一张图片试下（☺）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20188.jpg\n",
      "MIDDLE\n"
     ]
    }
   ],
   "source": [
    "i=random.choice(train.index)\n",
    "img_name=train.ID[i]\n",
    "print(img_name)\n",
    "img=Image.open(os.path.join(root_dir,'Train',img_name))\n",
    "img.show()\n",
    "print(train.Class[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 难点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们随机打开几张图片之后，可以发现图片之间的差别比较大。大家感受下：\n",
    "1. 质量好的图片：\n",
    "\n",
    "    - Middle:![**Middle**](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/06/27022332/mid3.png)\n",
    "    - Young:![**Young**](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/06/27022132/y2.png)\n",
    "    - Old:![**Old**](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/06/27022442/old1.png)\n",
    "2. 质量差的：\n",
    "    - Middle:![**Middle**](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/06/27022313/mid1.png)\n",
    "    \n",
    "下面是我们需要面临的问题：\n",
    "1. 图片的尺寸差别：有的图片的尺寸是66x46,而另一张图片尺寸为102x87\n",
    "2. 人物面貌角度不同：\n",
    "    - 侧脸：![](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/06/27022102/side1.png)\n",
    "    - 正脸：![](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/06/27022113/try1.png)\n",
    "3. 图片质量不一（直接上图）:\n",
    "    ![插图](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/06/27022450/pixel1.png)\n",
    "4. 亮度和对比度的差异\n",
    "    ![亮度](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/06/27022151/contra1.png)\n",
    "    ![对比度](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/06/27022200/contra2.png)\n",
    "现在，我们只专注下图片尺寸处理，将每一张图片尺寸重置为32x32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 格式化图片尺寸和将图片转换成numpy数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19906, 32, 32, 3)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "temp=[]\n",
    "for img_name in train.ID:\n",
    "    img_path=os.path.join(root_dir,'Train',img_name)\n",
    "    img=Image.open(img_path)\n",
    "    img=img.resize((32,32))\n",
    "    array=np.array(img)\n",
    "    temp.append(array.astype('float32'))\n",
    "train_x=np.stack(temp)\n",
    "print(train_x.shape)\n",
    "print(train_x.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6636, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "temp=[]\n",
    "for img_name in test.ID:\n",
    "    img_path=os.path.join(root_dir,'Test',img_name)\n",
    "    img=Image.open(img_path)\n",
    "    img=img.resize((32,32))\n",
    "    array=np.array(img)\n",
    "    temp.append(array.astype('float32'))\n",
    "test_x=np.stack(temp)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外我们再归一化图像，这样会使模型训练的更快"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_x = train_x / 255.\n",
    "test_x = test_x / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看下图片年龄大致分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MIDDLE    0.542751\n",
       "YOUNG     0.336883\n",
       "OLD       0.120366\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Class.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['Class'] = 'MIDDLE'\n",
    "test.to_csv('sub01.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将目标变量处理虚拟列，能够使模型更容易接受识别它"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 ..., 0 0 0]\n",
      "[[ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " ..., \n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]]\n",
      "(19906, 3)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb=LabelEncoder()\n",
    "train_y=lb.fit_transform(train.Class)\n",
    "print(train_y)\n",
    "train_y=keras.utils.np_utils.to_categorical(train_y)\n",
    "print(train_y)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#构建神经网络\n",
    "input_num_units=(32,32,3)\n",
    "hidden_num_units=500\n",
    "output_num_units=3\n",
    "epochs=5\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 500)               1536500   \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 3)                 1503      \n",
      "=================================================================\n",
      "Total params: 1,538,003\n",
      "Trainable params: 1,538,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,InputLayer\n",
    "model=Sequential({\n",
    "    InputLayer(input_shape=input_num_units),\n",
    "    Flatten(),\n",
    "    Dense(units=hidden_num_units,activation='relu'),\n",
    "    Dense(input_shape=(32,32,3),units=output_num_units,activation='softmax')\n",
    "})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 编译模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "19906/19906 [==============================] - 4s - loss: 0.8878 - acc: 0.5809     \n",
      "Epoch 2/5\n",
      "19906/19906 [==============================] - 4s - loss: 0.8420 - acc: 0.6077     \n",
      "Epoch 3/5\n",
      "19906/19906 [==============================] - 4s - loss: 0.8210 - acc: 0.6214     \n",
      "Epoch 4/5\n",
      "19906/19906 [==============================] - 4s - loss: 0.8149 - acc: 0.6194     \n",
      "Epoch 5/5\n",
      "19906/19906 [==============================] - 4s - loss: 0.8042 - acc: 0.6305     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d3803e6278>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.compile(optimizer='sgd',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_x,train_y,batch_size=batch_size,epochs=epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15924 samples, validate on 3982 samples\n",
      "Epoch 1/5\n",
      "15924/15924 [==============================] - 3s - loss: 0.7970 - acc: 0.6375 - val_loss: 0.7854 - val_acc: 0.6396\n",
      "Epoch 2/5\n",
      "15924/15924 [==============================] - 3s - loss: 0.7919 - acc: 0.6378 - val_loss: 0.7767 - val_acc: 0.6519\n",
      "Epoch 3/5\n",
      "15924/15924 [==============================] - 3s - loss: 0.7870 - acc: 0.6404 - val_loss: 0.7754 - val_acc: 0.6534\n",
      "Epoch 4/5\n",
      "15924/15924 [==============================] - 3s - loss: 0.7806 - acc: 0.6439 - val_loss: 0.7715 - val_acc: 0.6524\n",
      "Epoch 5/5\n",
      "15924/15924 [==============================] - 3s - loss: 0.7755 - acc: 0.6519 - val_loss: 0.7970 - val_acc: 0.6346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d3800a4eb8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size=batch_size,epochs=epochs,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用最基本的模型来处理这个年龄预测结果，并且最终的预测结果为0.6375。接下来，从以下角度尝试优化：\n",
    "1. 使用更好的神经网络模型\n",
    "2. 增加训练次数\n",
    "3. 将图片进行灰度处理（因为对于本问题而言，图片颜色不是一个特别重要的特征。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimize1 使用卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "添加卷积层之后，预测准确率有所上涨，从6.3到6.7；最开始epochs轮数是5，训练轮数增加到10，此时准确率为6.87；然后将训练轮数增加到20，结果没有发生变化。\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2D层\n",
    "\n",
    "`keras.layers.convolutional.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)`\n",
    "- filters:输出的维度\n",
    "- strides:卷积的步长\n",
    "\n",
    "更多关于Conv2D的介绍请看[Keras文档Conv2D层](http://keras-cn.readthedocs.io/en/latest/layers/convolutional_layer/#conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#参数初始化\n",
    "filters=10\n",
    "filtersize=(5,5)\n",
    "\n",
    "epochs =10\n",
    "batchsize=128\n",
    "\n",
    "input_shape=(32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13934 samples, validate on 5972 samples\n",
      "Epoch 1/10\n",
      "13934/13934 [==============================] - 9s - loss: 0.8986 - acc: 0.5884 - val_loss: 0.8352 - val_acc: 0.6271\n",
      "Epoch 2/10\n",
      "13934/13934 [==============================] - 9s - loss: 0.8141 - acc: 0.6281 - val_loss: 0.7886 - val_acc: 0.6474\n",
      "Epoch 3/10\n",
      "13934/13934 [==============================] - 9s - loss: 0.7788 - acc: 0.6504 - val_loss: 0.7706 - val_acc: 0.6551\n",
      "Epoch 4/10\n",
      "13934/13934 [==============================] - 9s - loss: 0.7638 - acc: 0.6577 - val_loss: 0.7559 - val_acc: 0.6626\n",
      "Epoch 5/10\n",
      "13934/13934 [==============================] - 9s - loss: 0.7484 - acc: 0.6679 - val_loss: 0.7457 - val_acc: 0.6710\n",
      "Epoch 6/10\n",
      "13934/13934 [==============================] - 9s - loss: 0.7346 - acc: 0.6723 - val_loss: 0.7490 - val_acc: 0.6780\n",
      "Epoch 7/10\n",
      "13934/13934 [==============================] - 9s - loss: 0.7217 - acc: 0.6804 - val_loss: 0.7298 - val_acc: 0.6795\n",
      "Epoch 8/10\n",
      "13934/13934 [==============================] - 9s - loss: 0.7162 - acc: 0.6826 - val_loss: 0.7248 - val_acc: 0.6792\n",
      "Epoch 9/10\n",
      "13934/13934 [==============================] - 9s - loss: 0.7082 - acc: 0.6892 - val_loss: 0.7202 - val_acc: 0.6890\n",
      "Epoch 10/10\n",
      "13934/13934 [==============================] - 9s - loss: 0.7001 - acc: 0.6940 - val_loss: 0.7226 - val_acc: 0.6885\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 10)        760       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1960)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 5883      \n",
      "=================================================================\n",
      "Total params: 6,643\n",
      "Trainable params: 6,643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "\n",
    "model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "\n",
    "model.add(keras.layers.convolutional.Conv2D(filters, filtersize, strides=(1, 1), padding='valid', data_format=\"channels_last\", activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "model.add(keras.layers.Dense(units=3, input_dim=50,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, epochs=epochs, batch_size=batchsize,validation_split=0.3)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimize2 增加神经网络的层数\n",
    "\n",
    "我们在模型中多添加几层并且提高卷几层的输出维度，这次结果得到显著提升：7.50904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#参数初始化\n",
    "filters1=50\n",
    "filters2=100\n",
    "filters3=100\n",
    "\n",
    "filtersize=(5,5)\n",
    "\n",
    "epochs =10\n",
    "batchsize=128\n",
    "\n",
    "input_shape=(32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13934 samples, validate on 5972 samples\n",
      "Epoch 1/10\n",
      "13934/13934 [==============================] - 44s - loss: 0.8613 - acc: 0.5985 - val_loss: 0.7778 - val_acc: 0.6586\n",
      "Epoch 2/10\n",
      "13934/13934 [==============================] - 44s - loss: 0.7493 - acc: 0.6697 - val_loss: 0.7545 - val_acc: 0.6808\n",
      "Epoch 3/10\n",
      "13934/13934 [==============================] - 43s - loss: 0.7079 - acc: 0.6877 - val_loss: 0.7150 - val_acc: 0.6947\n",
      "Epoch 4/10\n",
      "13934/13934 [==============================] - 43s - loss: 0.6694 - acc: 0.7061 - val_loss: 0.6496 - val_acc: 0.7261\n",
      "Epoch 5/10\n",
      "13934/13934 [==============================] - 43s - loss: 0.6274 - acc: 0.7295 - val_loss: 0.6683 - val_acc: 0.7125\n",
      "Epoch 6/10\n",
      "13934/13934 [==============================] - 43s - loss: 0.5950 - acc: 0.7462 - val_loss: 0.6194 - val_acc: 0.7400\n",
      "Epoch 7/10\n",
      "13934/13934 [==============================] - 43s - loss: 0.5562 - acc: 0.7655 - val_loss: 0.5981 - val_acc: 0.7465\n",
      "Epoch 8/10\n",
      "13934/13934 [==============================] - 43s - loss: 0.5165 - acc: 0.7852 - val_loss: 0.6458 - val_acc: 0.7354\n",
      "Epoch 9/10\n",
      "13934/13934 [==============================] - 46s - loss: 0.4826 - acc: 0.7986 - val_loss: 0.6206 - val_acc: 0.7467\n",
      "Epoch 10/10\n",
      "13934/13934 [==============================] - 45s - loss: 0.4530 - acc: 0.8130 - val_loss: 0.5984 - val_acc: 0.7569\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 28, 28, 50)        3800      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 10, 10, 100)       125100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 5, 5, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 1, 1, 100)         250100    \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 379,303\n",
      "Trainable params: 379,303\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "\n",
    "model.add(keras.layers.convolutional.Conv2D(filters1, filtersize, strides=(1, 1), padding='valid', data_format=\"channels_last\", activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.convolutional.Conv2D(filters2, filtersize, strides=(1, 1), padding='valid', data_format=\"channels_last\", activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.convolutional.Conv2D(filters3, filtersize, strides=(1, 1), padding='valid', data_format=\"channels_last\", activation='relu'))\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "model.add(keras.layers.Dense(units=3, input_dim=50,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, epochs=epochs, batch_size=batchsize,validation_split=0.3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6636/6636 [==============================] - 7s     \n",
      "['MIDDLE' 'YOUNG' 'MIDDLE' ..., 'MIDDLE' 'MIDDLE' 'YOUNG']\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict_classes(test_x)\n",
    "pred=lb.inverse_transform(pred)\n",
    "print(pred)\n",
    "test['Class']=pred\n",
    "test.to_csv('sub02.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19872/19906 [============================>.] - ETA: 0sOriginal: MIDDLE Predicted: MIDDLE\n"
     ]
    }
   ],
   "source": [
    "i = random.choice(train.index)\n",
    "img_name = train.ID[i]\n",
    "\n",
    "img=Image.open(os.path.join(root_dir,'Train',img_name))\n",
    "img.show()\n",
    "pred = model.predict_classes(train_x)\n",
    "print('Original:', train.Class[i], 'Predicted:', lb.inverse_transform(pred[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
